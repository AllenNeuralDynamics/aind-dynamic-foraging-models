{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation and parameter recovery of dynamic foraging task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -e /root/capsule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from aind_behavior_gym.dynamic_foraging.task import CoupledBlockTask, UncoupledBlockTask\n",
    "from aind_dynamic_foraging_models.generative_model import ForagerCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all foragers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forager_collection = ForagerCollection()\n",
    "df = forager_collection.get_all_foragers()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"agent_class_name\", \"preset_name\", \"n_free_params\", \"params\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize an agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "forager_gen = ForagerCollection().get_preset_forager(\"CompareToThreshold\", seed=42)\n",
    "forager_gen.set_params(\n",
    "    threshold=0.2,\n",
    "    learn_rate=0.3,\n",
    "    softmax_inverse_temperature=10,\n",
    "    biasL=3,\n",
    ")\n",
    "\n",
    "# forager_gen = ForagerCollection().get_preset_forager(\"Hattori2019\", seed=42)\n",
    "# forager_gen.set_params(\n",
    "#     learn_rate_rew=0.2659, \n",
    "#     learn_rate_unrew=0.0643, \n",
    "#     forget_rate_unchosen=0.5541,\n",
    "#     softmax_inverse_temperature=5.1442,\n",
    "#     biasL=0.5099,\n",
    "# )\n",
    "\n",
    "# forager_gen = ForagerCollection().get_preset_forager(\"Rescorla-Wagner\", seed=42)\n",
    "# forager_gen.set_params(\n",
    "#     biasL=0,\n",
    "# )\n",
    "\n",
    "\n",
    "# Create the task environment\n",
    "# task = CoupledBlockTask(reward_baiting=True, num_trials=1000, seed=42)\n",
    "task = UncoupledBlockTask(reward_baiting=False, num_trials=1000, seed=53)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model\n",
    "forager_gen.perform(task)\n",
    "\n",
    "# Capture the results\n",
    "ground_truth_params = forager_gen.params.model_dump()\n",
    "ground_truth_choice_prob = forager_gen.choice_prob\n",
    "# ground_truth_value = forager_gen.value\n",
    "# Get the history\n",
    "choice_history = forager_gen.get_choice_history()\n",
    "reward_history = forager_gen.get_reward_history()\n",
    "\n",
    "# Plot the session results\n",
    "fig, axes = forager_gen.plot_session(if_plot_latent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to recover parameters\n",
    "forager_fit = ForagerCollection().get_preset_forager(\"CompareToThreshold\", seed=42)\n",
    "# forager_fit = ForagerCollection().get_preset_forager(\"Hattori2019\", seed=42)\n",
    "forager_fit.fit(\n",
    "    choice_history,\n",
    "    reward_history,\n",
    "    # fit_bounds_override={\"softmax_inverse_temperature\": [0, 100]},\n",
    "    clamp_params={\n",
    "        # \"biasL\": 0, \n",
    "        # \"softmax_inverse_temperature\": 5.0\n",
    "    },\n",
    "    DE_kwargs=dict(\n",
    "        workers=4, \n",
    "        disp=True, \n",
    "        seed=np.random.default_rng(42)\n",
    "    ),\n",
    "    k_fold_cross_validation=None,\n",
    ")\n",
    "\n",
    "fitting_result = forager_fit.fitting_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check fitted parameters\n",
    "fit_names = fitting_result.fit_settings[\"fit_names\"]\n",
    "ground_truth = [num for name, num in ground_truth_params.items() if name in fit_names]\n",
    "print(f\"Num of trials: {len(choice_history)}\")\n",
    "print(f\"Fitted parameters: {fit_names}\")\n",
    "print(f'Ground truth: {[f\"{num:.4f}\" for num in ground_truth]}')\n",
    "print(f'Fitted:       {[f\"{num:.4f}\" for num in fitting_result.x]}')\n",
    "print(f\"Likelihood-Per-Trial: {fitting_result.LPT}\")\n",
    "print(f\"Prediction accuracy full dataset: {fitting_result.prediction_accuracy}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the fitted session results\n",
    "fig_fitting, axes = forager_fit.plot_fitted_session(if_plot_latent=True)\n",
    "\n",
    "# Overlay the ground truth Q-values for comparison\n",
    "# axes[0].plot(ground_truth_q_value[0], lw=1, color=\"red\", ls=\"-\", label=\"actual_Q(L)\")\n",
    "# axes[0].plot(ground_truth_q_value[1], lw=1, color=\"blue\", ls=\"-\", label=\"actual_Q(R)\")\"\"\n",
    "# axes[0].legend(fontsize=6, loc=\"upper left\", bbox_to_anchor=(0.6, 1.3), ncol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
