{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "from aind_behavior_gym.dynamic_foraging.task import CoupledBlockTask, UncoupledBlockTask\n",
    "from aind_dynamic_foraging_models.generative_model import ForagerCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynwb import NWBHDF5IO\n",
    "\n",
    "LOCAL_NWB_TMP = \"/data/foraging_nwb_bonsai\"\n",
    "\n",
    "def get_nwb_from_local_tmp(session_id):\n",
    "    \"\"\"Get NWB file from session_id.\n",
    "\n",
    "    Overwrite this function to get NWB file from other places.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    session_id : _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    io = NWBHDF5IO(f\"{LOCAL_NWB_TMP}/{session_id}.nwb\", mode=\"r\")\n",
    "    nwb = io.read()\n",
    "    return nwb\n",
    "\n",
    "\n",
    "def get_history_from_nwb(nwb):\n",
    "    \"\"\"Get choice and reward history from nwb file\n",
    "    \n",
    "    #TODO move this to aind-behavior-nwb-util\n",
    "    \"\"\"\n",
    "\n",
    "    df_trial = nwb.trials.to_dataframe()\n",
    "\n",
    "    autowater_offered = (df_trial.auto_waterL == 1) | (df_trial.auto_waterR == 1)\n",
    "    choice_history = df_trial.animal_response.map({0: 0, 1: 1, 2: np.nan}).values\n",
    "    reward_history = df_trial.rewarded_historyL | df_trial.rewarded_historyR\n",
    "    p_reward = [\n",
    "        df_trial.reward_probabilityL.values,\n",
    "        df_trial.reward_probabilityR.values,\n",
    "    ]\n",
    "    random_number = [\n",
    "        df_trial.reward_random_number_left.values,\n",
    "        df_trial.reward_random_number_right.values,\n",
    "    ]\n",
    "\n",
    "    baiting = False if \"without baiting\" in nwb.protocol.lower() else True\n",
    "\n",
    "    return (\n",
    "        baiting,\n",
    "        choice_history,\n",
    "        reward_history,\n",
    "        p_reward,\n",
    "        autowater_offered,\n",
    "        random_number,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject_id = '781370'  # uncoupled, no baiting\n",
    "# subject_id = '764769'  # uncoupled, baiting\n",
    "# subject_id = '776293'  # uncoupled, baiting\n",
    "subject_id = '769884'  # uncoupled, baiting\n",
    "\n",
    "\n",
    "\n",
    "for session_name in sorted(glob.glob(f'{LOCAL_NWB_TMP}/{subject_id}_*'), reverse=True):\n",
    "    print('############################################')\n",
    "    session_id = session_name.split('/')[-1].split('.')[0]\n",
    "    print(session_id)\n",
    "\n",
    "    nwb = get_nwb_from_local_tmp(session_id=session_id)\n",
    "    (\n",
    "        baiting,\n",
    "        choice_history,\n",
    "        reward_history,\n",
    "        _,\n",
    "        autowater_offered,\n",
    "        random_number,\n",
    "    ) = get_history_from_nwb(nwb)\n",
    "\n",
    "\n",
    "    # Remove NaNs\n",
    "    ignored = np.isnan(choice_history)\n",
    "    choice_history = choice_history[~ignored]\n",
    "    reward_history = reward_history[~ignored].to_numpy()\n",
    "    \n",
    "    # handle invalid sessions if there are too few trials\n",
    "    # -- Skip if len(valid trials) < 50 --\n",
    "    if len(choice_history) < 10:\n",
    "        fit_result = {\n",
    "            \"status\": \"skipped. valid trials < 50\",\n",
    "            \"upload_figs_s3\": {},\n",
    "            \"upload_pkls_s3\": {},\n",
    "            \"upload_record_docDB\": {},\n",
    "        }\n",
    "        print(f\"Skipping session {session_id} due to too few trials n={len(choice_history)}.\")\n",
    "    \n",
    "    else:\n",
    "        # -- Initialize model --\n",
    "        # forager = ForagerCollection().get_forager(\n",
    "        #     agent_class_name=\"ForagerCompareThreshold\",\n",
    "        #     agent_kwargs={\n",
    "        #         'choice_kernel': \"none\",\n",
    "        #     },\n",
    "        # )\n",
    "        forager_ctt = ForagerCollection().get_preset_forager(\"CompareToThreshold\")\n",
    "        fitting_result_ctt, _ = forager_ctt.fit(\n",
    "            choice_history,\n",
    "            reward_history,\n",
    "            clamp_params={\n",
    "                # \"biasL\": 0, \n",
    "                # \"softmax_inverse_temperature\": 5.0\n",
    "            },\n",
    "            DE_kwargs=dict(\n",
    "                workers=4, \n",
    "                disp=True, \n",
    "                seed=np.random.default_rng(42)\n",
    "            ),\n",
    "            # k_fold_cross_validation=None\n",
    "        )\n",
    "\n",
    "        forager_hattori = ForagerCollection().get_preset_forager(\"Hattori2019\")\n",
    "        fitting_result_hattori, _ = forager_hattori.fit(\n",
    "            choice_history,\n",
    "            reward_history,\n",
    "            DE_kwargs=dict(\n",
    "                workers=4, \n",
    "                disp=True, \n",
    "                seed=np.random.default_rng(42)\n",
    "            ),\n",
    "            # k_fold_cross_validation=None\n",
    "        )\n",
    "\n",
    "\n",
    "        # Check fitted parameters\n",
    "        for model_ind, fitting_result in enumerate([fitting_result_ctt, fitting_result_hattori]):\n",
    "            fit_names = fitting_result.fit_settings[\"fit_names\"]\n",
    "            print(f'Model: {['CompareToThreshold', 'Hattori'][model_ind]}')\n",
    "            print(f\"Num of trials: {len(choice_history)}\")\n",
    "            print(f\"Likelihood-Per-Trial: {fitting_result.LPT}\")\n",
    "            print(f\"AIC: {fitting_result.AIC}\")\n",
    "            print(f\"BIC: {fitting_result.BIC}\")\n",
    "            print(f\"Prediction accuracy full dataset: {fitting_result.prediction_accuracy}\")\n",
    "            print(f\"Fitted parameters: {fit_names}\")\n",
    "            print(f'Fitted:       {[f\"{num:.4f}\" for num in fitting_result.x]}\\n')\n",
    "\n",
    "        \n",
    "        fig_fitting_ctt, axes_ctt = forager_ctt.plot_fitted_session(if_plot_latent=True)\n",
    "        fig_fitting_hattori, axes_hattori = forager_hattori.plot_fitted_session(if_plot_latent=True)\n",
    "\n",
    "        fig_fitting_ctt.savefig(f'/results/{session_id}-ctt.png', dpi=150)\n",
    "        fig_fitting_hattori.savefig(f'/results/{session_id}-hattori.png', dpi=150)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Load data --\n",
    "# session_id = '781896_2025-04-10_14-11-57'\n",
    "\n",
    "# session_id = '781370_2025-02-03_11-09-28'\n",
    "# session_id = '781370_2025-02-05_11-25-51'\n",
    "session_id = '781370_2025-03-20_11-12-56'\n",
    "# session_id = '781370_2025-02-14_11-26-21'\n",
    "# session_id = '781370_2025-02-17_11-11-23'\n",
    "\n",
    "# session_id = '784806_2025-04-21_13-13-39'\n",
    "\n",
    "# session_id = '770527_2025-01-15_11-01-55'\n",
    "\n",
    "# session_id = '739977_2024-10-03_09-04-34'\n",
    "\n",
    "# session_id = '786866_2025-04-10_11-24-47'\n",
    "\n",
    "\n",
    "nwb = get_nwb_from_local_tmp(session_id=session_id)\n",
    "(\n",
    "    baiting,\n",
    "    choice_history,\n",
    "    reward_history,\n",
    "    _,\n",
    "    autowater_offered,\n",
    "    random_number,\n",
    ") = get_history_from_nwb(nwb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaNs\n",
    "ignored = np.isnan(choice_history)\n",
    "choice_history = choice_history[~ignored]\n",
    "reward_history = reward_history[~ignored].to_numpy()\n",
    "\n",
    "# -- Skip if len(valid trials) < 50 --\n",
    "if len(choice_history) < 50:\n",
    "    fit_result = {\n",
    "        \"status\": \"skipped. valid trials < 50\",\n",
    "        \"upload_figs_s3\": {},\n",
    "        \"upload_pkls_s3\": {},\n",
    "        \"upload_record_docDB\": {},\n",
    "    }\n",
    "\n",
    "# -- Initialize model --\n",
    "# forager = ForagerCollection().get_forager(\n",
    "#     agent_class_name=\"ForagerCompareThreshold\",\n",
    "#     agent_kwargs={\n",
    "#         'choice_kernel': \"none\",\n",
    "#     },\n",
    "# )\n",
    "\n",
    "forager_ctt = ForagerCollection().get_preset_forager(\"CompareToThreshold\")\n",
    "fitting_result_ctt, _ = forager_ctt.fit(\n",
    "    choice_history,\n",
    "    reward_history,\n",
    "    clamp_params={\n",
    "        # \"biasL\": 0, \n",
    "        # \"softmax_inverse_temperature\": 5.0\n",
    "    },\n",
    "    DE_kwargs=dict(\n",
    "        workers=4, \n",
    "        disp=True, \n",
    "        seed=np.random.default_rng(42)\n",
    "    ),\n",
    "    # k_fold_cross_validation=None\n",
    ")\n",
    "\n",
    "\n",
    "forager_hattori = ForagerCollection().get_preset_forager(\"Hattori2019\")\n",
    "fitting_result_hattori, _ = forager_hattori.fit(\n",
    "    choice_history,\n",
    "    reward_history,\n",
    "    DE_kwargs=dict(\n",
    "        workers=4, \n",
    "        disp=True, \n",
    "        seed=np.random.default_rng(42)\n",
    "    ),\n",
    "    # k_fold_cross_validation=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check fitted parameters\n",
    "for model_ind, fitting_result in enumerate([fitting_result_ctt, fitting_result_hattori]):\n",
    "    fit_names = fitting_result.fit_settings[\"fit_names\"]\n",
    "    print(f'Model: {['CompareToThreshold', 'Hattori'][model_ind]}')\n",
    "    print(f\"Num of trials: {len(choice_history)}\")\n",
    "    print(f\"Likelihood-Per-Trial: {fitting_result.LPT}\")\n",
    "    print(f\"AIC: {fitting_result.AIC}\")\n",
    "    print(f\"BIC: {fitting_result.BIC}\")\n",
    "    print(f\"Prediction accuracy full dataset: {fitting_result.prediction_accuracy}\")\n",
    "    print(f\"Fitted parameters: {fit_names}\")\n",
    "    print(f'Fitted:       {[f\"{num:.4f}\" for num in fitting_result.x]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_fitting, axes = forager_ctt.plot_fitted_session(if_plot_latent=True)\n",
    "fig_fitting, axes = forager_hattori.plot_fitted_session(if_plot_latent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
